{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56092b21",
   "metadata": {},
   "source": [
    "MSLR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49940e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# subprocess.run('wget https://ai2-s2-mslr.s3.us-west-2.amazonaws.com/mslr_data.tar.gz -O mslr_data.tar.gz', shell=True)\n",
    "# subprocess.run('tar -xvf mslr_data.tar.gz', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995213e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: dev-inputs.csv\n",
      "Rows: 5033, Columns: 5\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'PMID', 'Title', 'Abstract']\n",
      "\n",
      "File: dev-targets.csv\n",
      "Rows: 470, Columns: 3\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Target']\n",
      "\n",
      "File: test-inputs.csv\n",
      "Rows: 5678, Columns: 5\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'PMID', 'Title', 'Abstract']\n",
      "\n",
      "File: train-inputs.csv\n",
      "Rows: 40497, Columns: 5\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'PMID', 'Title', 'Abstract']\n",
      "\n",
      "File: train-targets.csv\n",
      "Rows: 3752, Columns: 3\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Target']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"mslr_data/cochrane\"\n",
    "stats = []\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    if os.path.isfile(filepath) and filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filepath)\n",
    "        stat = {\n",
    "            \"file\": filename,\n",
    "            \"rows\": len(df),\n",
    "            \"columns\": len(df.columns),\n",
    "            \"column_names\": list(df.columns)\n",
    "        }\n",
    "        stats.append(stat)\n",
    "\n",
    "for stat in stats:\n",
    "    print(f\"File: {stat['file']}\")\n",
    "    print(f\"Rows: {stat['rows']}, Columns: {stat['columns']}\")\n",
    "    print(f\"Column names: {stat['column_names']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276f4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: dev-inputs.csv\n",
      "Rows: 49002, Columns: 5\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'PMID', 'Title', 'Abstract']\n",
      "\n",
      "File: dev-reviews-info.csv\n",
      "Rows: 2021, Columns: 3\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Background']\n",
      "\n",
      "File: dev-targets.csv\n",
      "Rows: 2021, Columns: 4\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Target', 'Background']\n",
      "\n",
      "File: test-inputs.csv\n",
      "Rows: 42723, Columns: 5\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'PMID', 'Title', 'Abstract']\n",
      "\n",
      "File: test-reviews-info.csv\n",
      "Rows: 1667, Columns: 3\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Background']\n",
      "\n",
      "File: train-inputs.csv\n",
      "Rows: 323608, Columns: 5\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'PMID', 'Title', 'Abstract']\n",
      "\n",
      "File: train-reviews-info.csv\n",
      "Rows: 14191, Columns: 3\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Background']\n",
      "\n",
      "File: train-targets.csv\n",
      "Rows: 14191, Columns: 4\n",
      "Column names: ['Unnamed: 0', 'ReviewID', 'Target', 'Background']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"mslr_data/ms2\"\n",
    "stats = []\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    if os.path.isfile(filepath) and filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filepath)\n",
    "        stat = {\n",
    "            \"file\": filename,\n",
    "            \"rows\": len(df),\n",
    "            \"columns\": len(df.columns),\n",
    "            \"column_names\": list(df.columns)\n",
    "        }\n",
    "        stats.append(stat)\n",
    "\n",
    "for stat in stats:\n",
    "    print(f\"File: {stat['file']}\")\n",
    "    print(f\"Rows: {stat['rows']}, Columns: {stat['columns']}\")\n",
    "    print(f\"Column names: {stat['column_names']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f94ba6",
   "metadata": {},
   "source": [
    "ELife and PLOS journal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baece4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# result = subprocess.run(['tar', '-xvf', r'.\\drive-download-20251001T155819Z-1-001.zip'], capture_output=True, text=True)\n",
    "# print(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d033f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: test_eLife_docs.jsonl\n",
      "Rows: 142, Columns: 4\n",
      "Column names: ['article', 'headings', 'keywords', 'id']\n",
      "\n",
      "File: test_eLife_laysums.txt\n",
      "Rows: 143, Columns: 1\n",
      "Column names: ['text']\n",
      "\n",
      "File: test_PLOS_docs.jsonl\n",
      "Rows: 142, Columns: 4\n",
      "Column names: ['article', 'headings', 'keywords', 'id']\n",
      "\n",
      "File: test_PLOS_laysums.txt\n",
      "Rows: 143, Columns: 1\n",
      "Column names: ['text']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "elife_plos_stats = []\n",
    "elife_plos_dir = \"eLife_PLOS_data\"\n",
    "for filename in os.listdir(elife_plos_dir):\n",
    "    filepath = os.path.join(elife_plos_dir, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        if filename.endswith('.jsonl'):\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    sample = json.loads(lines[0])\n",
    "                    columns = list(sample.keys())\n",
    "                else:\n",
    "                    columns = []\n",
    "                stat = {\n",
    "                    \"file\": filename,\n",
    "                    \"rows\": len(lines),\n",
    "                    \"columns\": len(columns),\n",
    "                    \"column_names\": columns\n",
    "                }\n",
    "                elife_plos_stats.append(stat)\n",
    "        elif filename.endswith('.txt'):\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                stat = {\n",
    "                    \"file\": filename,\n",
    "                    \"rows\": content.count('\\n') + 1 if content else 0,\n",
    "                    \"columns\": 1,\n",
    "                    \"column_names\": [\"text\"]\n",
    "                }\n",
    "                elife_plos_stats.append(stat)\n",
    "\n",
    "for stat in elife_plos_stats:\n",
    "    print(f\"File: {stat['file']}\")\n",
    "    print(f\"Rows: {stat['rows']}, Columns: {stat['columns']}\")\n",
    "    print(f\"Column names: {stat['column_names']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
