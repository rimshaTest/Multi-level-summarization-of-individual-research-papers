# Multi-level-summarization-of-individual-research-papers
Summary
Research papers can be intimidating and challenging for readers, creating reluctance in the general public to learn about research breakthroughs and broaden their knowledge. This project aims to finetune text simplification and summarization, two challenging NLP (Natural Language Processing) tasks that become especially complex when applied to dense scientific literature, to allow the simplification of any individual research papers to three different reading levels: kids, teens, and adults.

Existing projects have achieved good performances on general educational literature or articles, but are still unable to perform well on scientific research papers due to domain-specific nuances and varied terminology. We hypothesize that domain-specific fine-tuning on scientific corpora will significantly improve readability metrics compared to general-purpose simplification models. Our goal is to explore the capabilities of transformer-based architectures and fine-tuned LLMs to bridge this gap.

Download the eLife and PLOS datasets from [here](https://github.com/TGoldsack1/Corpora_for_Lay_Summarisation).
